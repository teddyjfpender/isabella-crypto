name: Benchmarks

on:
  push:
    tags:
      - 'v*'
  workflow_dispatch:
    inputs:
      sizes:
        description: 'Input sizes (comma-separated)'
        required: false
        default: '10,100,1000'
      iterations:
        description: 'Number of iterations'
        required: false
        default: '10'

jobs:
  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Haskell
        uses: haskell-actions/setup@v2
        with:
          ghc-version: '9.8'
          cabal-version: '3.10'

      - name: Setup OCaml
        uses: ocaml/setup-ocaml@v3
        with:
          ocaml-compiler: '5.2'

      - name: Setup Node.js
        uses: actions/setup-node@v6
        with:
          node-version: '22'

      - name: Install OCaml dependencies
        run: |
          opam install -y dune zarith zarith_stubs_js js_of_ocaml js_of_ocaml-ppx

      - name: Build Haskell
        working-directory: isabella.hs
        run: |
          cabal update
          cabal build all

      - name: Build OCaml
        working-directory: isabella.ml
        run: |
          eval $(opam env)
          dune build

      - name: Build JavaScript
        run: |
          eval $(opam env)
          cd isabella.ml && dune build src/js/isabella_js.bc.js
          mkdir -p isabella.ts/src
          cp isabella.ml/_build/default/src/js/isabella_js.bc.js isabella.ts/src/isabella.js

      - name: Run benchmarks
        run: |
          SIZES="${{ github.event.inputs.sizes || '10,100,1000' }}"
          ITERATIONS="${{ github.event.inputs.iterations || '10' }}"

          eval $(opam env)
          if [[ -f bench/run-benchmarks.sh ]]; then
            ./bench/run-benchmarks.sh \
              --sizes "$SIZES" \
              --iterations "$ITERATIONS" \
              --languages "haskell,ocaml,javascript"
          else
            echo "Benchmark script not found, skipping"
          fi

      - name: Generate summary
        run: |
          if [[ -f bench/summarize.sh ]]; then
            ./bench/summarize.sh
          else
            echo "No benchmark summary available"
          fi

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: benchmark-results
          path: bench/data/
          retention-days: 90
          if-no-files-found: ignore

      - name: Post summary to job
        run: |
          echo "## Benchmark Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [[ -f bench/summarize.sh ]]; then
            echo '```' >> $GITHUB_STEP_SUMMARY
            ./bench/summarize.sh >> $GITHUB_STEP_SUMMARY 2>/dev/null || echo "No results"
            echo '```' >> $GITHUB_STEP_SUMMARY
          else
            echo "Benchmark infrastructure not yet configured." >> $GITHUB_STEP_SUMMARY
          fi
